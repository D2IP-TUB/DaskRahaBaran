{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Data Cleaning Pipeline with Raha and Baran (Minimal and Integrated)\n",
    "We build an end-to-end data cleaning pipeline with our configuration-free error detection and correction systems, Raha and Baran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import IPython.display\n",
    "import ipywidgets\n",
    "\n",
    "import raha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instantiating the Detection and Correction Classes\n",
    "We first instantiate the `Detection` and `Correction` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_1 = raha.dask_version.detection_parallel.Detection()\n",
    "app_2 = raha.dask_version.correction_parallel.Correction()\n",
    "\n",
    "# How many tuples would you label?\n",
    "app_1.LABELING_BUDGET = 20\n",
    "app_2.LABELING_BUDGET = 0\n",
    "\n",
    "# Would you like to see the logs?\n",
    "app_1.VERBOSE = True\n",
    "app_2.VERBOSE = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Instantiating the Dataset\n",
    "We next load and instantiate the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_name</th>\n",
       "      <th>l_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>area_code</th>\n",
       "      <th>phone</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>has_child</th>\n",
       "      <th>salary</th>\n",
       "      <th>rate</th>\n",
       "      <th>single_exemp</th>\n",
       "      <th>married_exemp</th>\n",
       "      <th>child_exemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pengyuan</td>\n",
       "      <td>Zendler</td>\n",
       "      <td>F</td>\n",
       "      <td>508</td>\n",
       "      <td>744-9007</td>\n",
       "      <td>SWAMPSCOTT</td>\n",
       "      <td>MA</td>\n",
       "      <td>01907</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>90000</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0</td>\n",
       "      <td>7150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nik</td>\n",
       "      <td>Tacic</td>\n",
       "      <td>M</td>\n",
       "      <td>702</td>\n",
       "      <td>517-7658</td>\n",
       "      <td>LAS VEGAS</td>\n",
       "      <td>NV</td>\n",
       "      <td>89140</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>90000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hovav</td>\n",
       "      <td>Punter</td>\n",
       "      <td>M</td>\n",
       "      <td>501</td>\n",
       "      <td>304-9763</td>\n",
       "      <td>HASTY</td>\n",
       "      <td>AR</td>\n",
       "      <td>72640</td>\n",
       "      <td>S</td>\n",
       "      <td>N</td>\n",
       "      <td>50000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xiangning</td>\n",
       "      <td>Vanneste</td>\n",
       "      <td>F</td>\n",
       "      <td>862</td>\n",
       "      <td>651-6469</td>\n",
       "      <td>BRIGANTINE</td>\n",
       "      <td>NJ</td>\n",
       "      <td>08203</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>55000</td>\n",
       "      <td>1.9519792</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Belen</td>\n",
       "      <td>Niccum</td>\n",
       "      <td>F</td>\n",
       "      <td>920</td>\n",
       "      <td>287-1889</td>\n",
       "      <td>FLORENCE</td>\n",
       "      <td>WI</td>\n",
       "      <td>54121</td>\n",
       "      <td>S</td>\n",
       "      <td>Y</td>\n",
       "      <td>85000</td>\n",
       "      <td>5.9232907</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      f_name    l_name gender area_code     phone        city state    zip   \n",
       "0   Pengyuan   Zendler      F       508  744-9007  SWAMPSCOTT    MA  01907  \\\n",
       "1        Nik     Tacic      M       702  517-7658   LAS VEGAS    NV  89140   \n",
       "2      Hovav    Punter      M       501  304-9763       HASTY    AR  72640   \n",
       "3  Xiangning  Vanneste      F       862  651-6469  BRIGANTINE    NJ  08203   \n",
       "4      Belen    Niccum      F       920  287-1889    FLORENCE    WI  54121   \n",
       "\n",
       "  marital_status has_child salary       rate single_exemp married_exemp   \n",
       "0              M         N  90000        5.3            0          7150  \\\n",
       "1              M         N  90000        0.0            0             0   \n",
       "2              S         N  50000        7.0           20             0   \n",
       "3              M         Y  55000  1.9519792            0          2000   \n",
       "4              S         Y  85000  5.9232907          700             0   \n",
       "\n",
       "  child_exemp  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3        1500  \n",
       "4         400  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dictionary = {\n",
    "    \"name\": \"toy\",\n",
    "    \"path\": \"../datasets/toy/dirty.csv\",\n",
    "    \"clean_path\": \"../datasets/toy/clean.csv\"\n",
    "}\n",
    "d = app_1.initialize_dataset(dataset_dictionary)\n",
    "d.dataframe.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generating Features and Clusters\n",
    "Raha runs (all or the promising) error detection strategies on the dataset. This step could take a while because all the strategies should be run on the dataset. Raha then generates a feature vector for each data cell based on the output of error detection strategies. Raha next builds a hierarchical clustering model for our clustering-based sampling approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9992 cells are detected by [\"PVD\", [\"l_name\", \"D\"]].\n",
      "1725 cells are detected by [\"PVD\", [\"f_name\", \"x\"]].\n",
      "71159 cells are detected by [\"PVD\", [\"zip\", \"9\"]].\n",
      "99628 cells are detected by [\"PVD\", [\"has_child\", \"Y\"]].\n",
      "0 cells are detected by [\"RVD\", [\"f_name\", \"gender\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"has_child\", \"marital_status\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"marital_status\", \"l_name\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"child_exemp\", \"l_name\"]].\n",
      "9532 cells are detected by [\"RVD\", [\"zip\", \"state\"]].\n",
      "83040 cells are detected by [\"PVD\", [\"zip\", \"5\"]].\n",
      "77246 cells are detected by [\"PVD\", [\"zip\", \"6\"]].\n",
      "399824 cells are detected by [\"RVD\", [\"f_name\", \"single_exemp\"]].\n",
      "6559 cells are detected by [\"PVD\", [\"f_name\", \"P\"]].\n",
      "9896 cells are detected by [\"PVD\", [\"f_name\", \"R\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"state\", \"has_child\"]].\n",
      "39791 cells are detected by [\"PVD\", [\"f_name\", \"s\"]].\n",
      "10491 cells are detected by [\"PVD\", [\"f_name\", \"H\"]].\n",
      "3801 cells are detected by [\"PVD\", [\"state\", \"F\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"f_name\", \"l_name\"]].\n",
      "20173 cells are detected by [\"PVD\", [\"f_name\", \"S\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"f_name\", \"city\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"has_child\", \"zip\"]].\n",
      "20094 cells are detected by [\"PVD\", [\"salary\", \"6\"]].\n",
      "399812 cells are detected by [\"RVD\", [\"l_name\", \"child_exemp\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"married_exemp\", \"zip\"]].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Discarding ['Boo', 'Philippsen', 'F', '864', '762-2552', 'RICHLAND', 'SC', ''] (invalid length)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 cells are detected by [\"RVD\", [\"f_name\", \"state\"]].\n",
      "47242 cells are detected by [\"PVD\", [\"rate\", \"4\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"gender\", \"married_exemp\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"married_exemp\", \"f_name\"]].\n",
      "15347 cells are detected by [\"PVD\", [\"state\", \"S\"]].\n",
      "300092 cells are detected by [\"RVD\", [\"area_code\", \"single_exemp\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"single_exemp\", \"f_name\"]].\n",
      "194264 cells are detected by [\"PVD\", [\"child_exemp\", \"0\"]].\n",
      "109791 cells are detected by [\"PVD\", [\"city\", \"N\"]].\n",
      "10196 cells are detected by [\"PVD\", [\"l_name\", \"L\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"salary\", \"state\"]].\n",
      "9260 cells are detected by [\"RVD\", [\"phone\", \"salary\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"state\", \"city\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"gender\", \"has_child\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"marital_status\", \"has_child\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"marital_status\", \"rate\"]].\n",
      "254430 cells are detected by [\"RVD\", [\"married_exemp\", \"marital_status\"]].\n",
      "32199 cells are detected by [\"PVD\", [\"rate\", \"2\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"marital_status\", \"f_name\"]].\n",
      "106138 cells are detected by [\"PVD\", [\"phone\", \"3\"]].\n",
      "106426 cells are detected by [\"PVD\", [\"phone\", \"1\"]].\n",
      "1939 cells are detected by [\"PVD\", [\"child_exemp\", \"8\"]].\n",
      "20299 cells are detected by [\"PVD\", [\"salary\", \"9\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"salary\", \"phone\"]].\n",
      "1 cells are detected by [\"PVD\", [\"city\", \"/\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"rate\", \"gender\"]].\n",
      "28329 cells are detected by [\"PVD\", [\"l_name\", \"m\"]].\n",
      "7422 cells are detected by [\"PVD\", [\"f_name\", \"D\"]].\n",
      "334634 cells are detected by [\"RVD\", [\"rate\", \"state\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"state\", \"phone\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"single_exemp\", \"has_child\"]].\n",
      "30278 cells are detected by [\"PVD\", [\"l_name\", \"k\"]].\n",
      "171244 cells are detected by [\"KBVD\", \"/home/julian/Desktop/HiWi/DaskRahaBaran/raha/original/tools/KATARA/knowledge-base/zipHasCity.rel.txt\"].\n",
      "399600 cells are detected by [\"RVD\", [\"child_exemp\", \"married_exemp\"]].\n",
      "256642 cells are detected by [\"RVD\", [\"single_exemp\", \"marital_status\"]].\n",
      "218 cells are detected by [\"PVD\", [\"city\", \"-\"]].\n",
      "1559 cells are detected by [\"PVD\", [\"l_name\", \"U\"]].\n",
      "357844 cells are detected by [\"RVD\", [\"zip\", \"marital_status\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"rate\", \"marital_status\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"single_exemp\", \"salary\"]].\n",
      "78113 cells are detected by [\"PVD\", [\"l_name\", \"n\"]].\n",
      "2459 cells are detected by [\"PVD\", [\"f_name\", \"O\"]].\n",
      "45898 cells are detected by [\"PVD\", [\"city\", \" \"]].\n",
      "23084 cells are detected by [\"PVD\", [\"state\", \"C\"]].\n",
      "4526 cells are detected by [\"PVD\", [\"f_name\", \"W\"]].\n",
      "303830 cells are detected by [\"RVD\", [\"city\", \"rate\"]].\n",
      "694 cells are detected by [\"PVD\", [\"l_name\", \"'\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"has_child\", \"child_exemp\"]].\n",
      "40018 cells are detected by [\"PVD\", [\"rate\", \"9\"]].\n",
      "106632 cells are detected by [\"PVD\", [\"phone\", \"5\"]].\n",
      "112617 cells are detected by [\"PVD\", [\"area_code\", \"0\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"l_name\", \"city\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"marital_status\", \"single_exemp\"]].\n",
      "71867 cells are detected by [\"PVD\", [\"rate\", \"5\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"has_child\", \"rate\"]].\n",
      "106768 cells are detected by [\"PVD\", [\"phone\", \"4\"]].\n",
      "246750 cells are detected by [\"RVD\", [\"area_code\", \"rate\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"area_code\", \"phone\"]].\n",
      "42285 cells are detected by [\"PVD\", [\"state\", \"N\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"f_name\", \"phone\"]].\n",
      "46110 cells are detected by [\"PVD\", [\"area_code\", \"6\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"state\", \"l_name\"]].\n",
      "7718 cells are detected by [\"PVD\", [\"married_exemp\", \"7\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"area_code\", \"zip\"]].\n",
      "106831 cells are detected by [\"PVD\", [\"phone\", \"2\"]].\n",
      "11264 cells are detected by [\"PVD\", [\"state\", \"E\"]].\n",
      "399864 cells are detected by [\"RVD\", [\"l_name\", \"single_exemp\"]].\n",
      "33859 cells are detected by [\"OD\", [\"gaussian\", \"2.5\"]].\n",
      "3599 cells are detected by [\"PVD\", [\"f_name\", \"I\"]].\n",
      "187 cells are detected by [\"PVD\", [\"rate\", \"N\"]].\n",
      "3804 cells are detected by [\"PVD\", [\"state\", \"Z\"]].\n",
      "49483 cells are detected by [\"PVD\", [\"rate\", \"7\"]].\n",
      "3364 cells are detected by [\"PVD\", [\"f_name\", \"Z\"]].\n",
      "264428 cells are detected by [\"RVD\", [\"city\", \"zip\"]].\n",
      "86667 cells are detected by [\"PVD\", [\"zip\", \"2\"]].\n",
      "2869 cells are detected by [\"PVD\", [\"l_name\", \"Z\"]].\n",
      "46957 cells are detected by [\"PVD\", [\"f_name\", \"u\"]].\n",
      "29850 cells are detected by [\"PVD\", [\"salary\", \"1\"]].\n",
      "400000 cells are detected by [\"RVD\", [\"area_code\", \"gender\"]].\n"
     ]
    }
   ],
   "source": [
    "app_1.run_strategies(d)\n",
    "app_1.generate_features(d)\n",
    "app_1.build_clusters(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Interactive Tuple Sampling and Labeling\n",
    "Raha then iteratively samples a tuple. We should label data cells of each sampled tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def on_button_clicked(_):\n",
    "    for j in range(0, len(texts)):\n",
    "        cell = (d.sampled_tuple, j)\n",
    "        error_label = 0\n",
    "        correction = texts[j].value\n",
    "        if d.dataframe.iloc[cell] != correction:\n",
    "            error_label = 1\n",
    "        d.labeled_cells[cell] = [error_label, correction]\n",
    "    d.labeled_tuples[d.sampled_tuple] = 1\n",
    "\n",
    "app_1.sample_tuple(d)\n",
    "print(\"Fix the dirty cells in the following sampled tuple.\")\n",
    "sampled_tuple = pandas.DataFrame(data=[d.dataframe.iloc[d.sampled_tuple, :]], columns=d.dataframe.columns)\n",
    "IPython.display.display(sampled_tuple)  \n",
    "texts = [ipywidgets.Text(value=d.dataframe.iloc[d.sampled_tuple, j]) for j in range(d.dataframe.shape[1])]\n",
    "button = ipywidgets.Button(description=\"Save the Annotation\")\n",
    "button.on_click(on_button_clicked)\n",
    "output = ipywidgets.VBox(children=texts + [button])\n",
    "IPython.display.display(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of time, we use the ground truth of the dataset to label tuples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "while len(d.labeled_tuples) < app_1.LABELING_BUDGET:\n",
    "    app_1.sample_tuple(d)\n",
    "    if d.has_ground_truth:\n",
    "        app_1.label_with_ground_truth(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Propagating User Labels and Predicting the Labels\n",
    "Raha then propagates each user label through its cluster. Raha then trains and applies one classifier per data column to predict the label of the rest of data cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_1.propagate_labels(d)\n",
    "app_1.predict_labels(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initializing and Updating the Error Corrector Models\n",
    "Baran initializes the error corrector models. Baran then iteratively samples a tuple. We should label data cells of each sampled tuple. It then udpates the models accordingly and generates a feature vector for each pair of a data error and a correction candidate. Finally, it trains and applies a classifier to each data column to predict the final correction of each data error. Since we already labeled tuples for Raha, we use the same labeled tuples and do not label new tuples here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_2.initialize_models(d)\n",
    "app_2.initialize_dataset(d)\n",
    "for si in d.labeled_tuples:\n",
    "    d.sampled_tuple = si\n",
    "    app_2.update_models(d)\n",
    "    app_2.predict_corrections(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Storing Results\n",
    "Both Raha and Baran can also store the error detection/correction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_1.store_results(d)\n",
    "app_2.store_results(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluating the Data Cleaning Task\n",
    "We can finally evaluate our data cleaning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edp, edr, edf = d.get_data_cleaning_evaluation(d.detected_cells)[:3]\n",
    "ecp, ecr, ecf = d.get_data_cleaning_evaluation(d.corrected_cells)[-3:]\n",
    "\n",
    "evaluation_df = pandas.DataFrame(columns=[\"Task\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
    "evaluation_detection_df = pandas.DataFrame({\"Task\": \"Error Detection (Raha)\", \"Precision\": \"{:.2f}\".format(edp), \"Recall\": \"{:.2f}\".format(edr), \"F1 Score\": \"{:.2f}\".format(edf)}, index=[0])\n",
    "evaluation_correction_df = pandas.DataFrame({\"Task\": \"Error Correction (Baran)\", \"Precision\": \"{:.2f}\".format(ecp), \"Recall\": \"{:.2f}\".format(ecr), \"F1 Score\": \"{:.2f}\".format(ecf)}, index=[0])\n",
    "evaluation_df = pandas.concat([evaluation_df, evaluation_detection_df, evaluation_correction_df], ignore_index=True)\n",
    "evaluation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
